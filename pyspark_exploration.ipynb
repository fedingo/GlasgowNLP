{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "         .master(\"local[16]\") \\\n",
    "         .appName(\"Exp\") \\\n",
    "         .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.executor.memory\", \"8g\")\n",
    "spark.conf.set(\"spark.driver.memory\", \"8g\")\n",
    "spark.conf.set(\"spark.driver.maxResultSize\", \"4g\")\n",
    "spark.conf.set(\"spark.sql.broadcastTimeout\", \"900\")\n",
    "\n",
    "schema = StructType([StructField(\"value\", IntegerType(), True), StructField(\"name\", StringType(), True)])\n",
    "my_list = [[1, \"ciao\"],\n",
    "           [2, \"pippo\"],\n",
    "           [3, \"topolino\"],\n",
    "           [4, \"paperino\"]]\n",
    "\n",
    "df = spark.createDataFrame(my_list, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ciao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pippo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>topolino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>paperino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value      name\n",
       "0      1      ciao\n",
       "1      2     pippo\n",
       "2      3  topolino\n",
       "3      4  paperino"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "dataset = pq.ParquetDataset(\"people/\", use_legacy_dataset=True)\n",
    "\n",
    "dataset.read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447583"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "mumu_dir = '../mumu/MuMu_dataset/'\n",
    "\n",
    "db_review = []\n",
    "with open(mumu_dir + '/amazon_reviews_MuMu.json') as f:\n",
    "    for row in f.readlines():\n",
    "        db_review.append(json.loads(row))\n",
    "\n",
    "len(db_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31472, 147296)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "msd_id_map = {}\n",
    "count = 0\n",
    "\n",
    "\n",
    "with open(mumu_dir + '/MuMu_dataset_multi-label.csv') as csv_file:\n",
    "    db_metadata = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "    # Skip header row\n",
    "    for row in db_metadata:\n",
    "        msd_id_map[row[0]] = msd_id_map.get(row[0], []) + [row[2]]\n",
    "        count += 1\n",
    "\n",
    "# msd_id_map maps the amazon_ids to MSD_track_ids, to retrieve the actual information from the MSD dataset\n",
    "len(msd_id_map.keys()), count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae332c5103b4e18858d4e1d1a5be5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147296"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "\n",
    "with open(mumu_dir + '/MuMu_dataset_multi-label.csv') as csv_file:\n",
    "    db_metadata = csv.reader(csv_file, delimiter=',')\n",
    "    \n",
    "    msd_ids = set()\n",
    "    \n",
    "    for row in tqdm.tqdm(db_metadata):\n",
    "        msd_ids.add(row[2])\n",
    "        \n",
    "len(msd_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147295 993176 4444\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as sf\n",
    "\n",
    "mumu_dir = '../mumu/MuMu_dataset/'\n",
    "\n",
    "reviews = spark.read.json(mumu_dir + '/amazon_reviews_MuMu.json')\n",
    "reviews = reviews.drop(\"helpful\", \"overall\", \"reviewTime\", \"unixReviewTime\", \"reviewerName\")\n",
    "\n",
    "msd_map = spark.read.csv(mumu_dir + '/MuMu_dataset_multi-label.csv', header='true')\n",
    "msd_map = msd_map.drop(\"recording_mbid\")\n",
    "msd_map = msd_map.withColumn(\"MSD_track_id\", sf.substring(sf.col(\"MSD_track_id\"), 0, 17))\n",
    "msd_map = msd_map.withColumn(\"CLS_match\", sf.lit(1))\n",
    "\n",
    "path_map = spark.read.csv(\"../msd/mp3/MSD/dataset_annotation.csv\", header=\"true\")\n",
    "path_map = path_map.withColumnRenamed(\"id\", \"MSD_track_id\")\n",
    "\n",
    "base_path = \"/nfs/msd/mp3/MSD/audio/\"\n",
    "path_map = path_map.withColumn(\"path\", sf.concat(sf.lit(base_path), \n",
    "                                                 sf.lit(sf.col('filename').substr(1,1)),\n",
    "                                                 sf.lit(\"/\"),\n",
    "                                                 sf.lit(sf.col('filename').substr(2,1)),\n",
    "                                                 sf.lit(\"/\"),\n",
    "                                                 sf.col('filename')))\n",
    "\n",
    "\n",
    "msd_map = msd_map.repartition(80)\n",
    "path_map = path_map.repartition(80)\n",
    "reviews = reviews.sample(0.01).repartition(80)\n",
    "\n",
    "print(msd_map.count(), path_map.count(), reviews.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_path_map = path_map.join(msd_map, \"MSD_track_id\", how=\"leftsemi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, array\n",
    "from pyspark.sql.types import StringType\n",
    "from random import sample\n",
    "\n",
    "def get_negative_sample(amazon_id):\n",
    "    track_list = msd_id_map[amazon_id]\n",
    "    sampled_track_id = sample(msd_ids, 1)[0]\n",
    "    while sampled_track_id in track_list or sampled_track_id == \"MSD_track_id\":\n",
    "        sampled_track_id = sample(msd_ids, 1)[0]\n",
    "    return sampled_track_id[:-1]\n",
    "\n",
    "negatives_udf = udf(get_negative_sample, StringType())\n",
    "\n",
    "neg_msd = msd_map.withColumn(\"MSD_track_id\", negatives_udf(msd_map.amazon_id))\\\n",
    "                 .withColumn(\"CLS_match\", sf.lit(0))\n",
    "\n",
    "full_map = msd_map.unionByName(neg_msd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80, 160)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msd_map.rdd.getNumPartitions(), neg_msd.rdd.getNumPartitions(), full_map.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSD_track_id',\n",
       " 'amazon_id',\n",
       " 'genres',\n",
       " 'CLS_match',\n",
       " 'reviewText',\n",
       " 'reviewerID',\n",
       " 'summary',\n",
       " 'filename',\n",
       " 'label',\n",
       " 'path',\n",
       " 'id']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "full = full_map.join(reviews, \"amazon_id\").join(path_map, \"MSD_track_id\")\n",
    "full = full.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from source.io.pb_item import pb_Item\n",
    "import lmdb\n",
    "from pyspark.sql.functions import udf, array, struct\n",
    "\n",
    "def write_item(row):\n",
    "    \n",
    "    path = row[\"path\"]\n",
    "    CLS = str(row[\"CLS_match\"])\n",
    "    review = row[\"reviewText\"]\n",
    "    id = str(row[\"id\"])\n",
    "    #try:\n",
    "    x, sr = librosa.load(path, sr=None)\n",
    "    #except Exception as e:\n",
    "    #    return str(e)\n",
    "    \n",
    "    melspectrogram = librosa.feature.melspectrogram(x, sr)\n",
    "    log_mel = librosa.power_to_db(melspectrogram, ref=np.max)\n",
    "    features = np.transpose(log_mel)\n",
    "\n",
    "    pb_item = pb_Item(features=features,\n",
    "                      review=review,\n",
    "                      seq_class=CLS)\n",
    "\n",
    "    env = lmdb.open('data/MSD/spark.lmdb', subdir=False,\n",
    "            map_size=1e12 )\n",
    "\n",
    "    with env.begin(write=True) as txn:\n",
    "        txn.put(id.encode(), pb_item.get_pb_obj().SerializeToString())\n",
    "    \n",
    "    return 1\n",
    "        \n",
    "write_udf = udf(write_item, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full.withColumn(\"written\", write_udf(struct(\"*\")))\n",
    "\n",
    "env = lmdb.open('data/MSD/spark.lmdb', subdir=False,\n",
    "                map_size=1e12 )\n",
    "\n",
    "full.collect()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'psize': 4096,\n",
       " 'depth': 2,\n",
       " 'branch_pages': 1,\n",
       " 'leaf_pages': 6,\n",
       " 'overflow_pages': 359675,\n",
       " 'entries': 473}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------------+---------+--------------------+--------------+--------------------+----------------+------------------+--------------------+-------------+-------+\n",
      "|     MSD_track_id| amazon_id|              genres|CLS_match|          reviewText|    reviewerID|             summary|        filename|             label|                path|           id|written|\n",
      "+-----------------+----------+--------------------+---------+--------------------+--------------+--------------------+----------------+------------------+--------------------+-------------+-------+\n",
      "|TRGMCEI128F42B1B3|B00000I0VW|Alternative Rock,...|        1|WOW, this thing i...|A3MPOBQFYIMYG5|This album is lig...|3486416.clip.mp3|ARNUPIM11F4C83BD4D|/nfs/msd/mp3/MSD/...|  34359738371|      1|\n",
      "|TRWCKWW128F92D9D5|B0001M4DQO|Adult Contemporar...|        1|My first impressi...|A3OKT9G7MDJ0FX| don't throw it out!|3644324.clip.mp3|AR1PT6R1187B9A6D9A|/nfs/msd/mp3/MSD/...| 274877906945|      1|\n",
      "|TRNHSAC128F14560D|B000002JJY|Alternative Rock,...|        1|I still have this...|A1NLRPWEIV71HQ|I only review the...| 228552.clip.mp3|ARU2T6V1187FB5590B|/nfs/msd/mp3/MSD/...| 377957122048|      1|\n",
      "|TRIMUTE128F4220A2|B0000CG8DX|Alternative Rock,...|        1|OK, if you're rea...|A22YGU8ANJHTR9|unbelievable---ch...|1889376.clip.mp3|ARGJQFC11F50C487A2|/nfs/msd/mp3/MSD/...| 609885356033|      1|\n",
      "|TRCVOLK128F423EA9|B000002H9F|Alternative Rock,...|        1|I bought this ite...|A11WNWR060UBP5|     satisfying kids|2068848.clip.mp3|AR1E9AW1187B9AC8F6|/nfs/msd/mp3/MSD/...| 627065225223|      1|\n",
      "|TROYIHQ128F930CE4|B001E12ZF2|Noels,Adult Conte...|        0|The music is very...| A6HFLU8ZZMO50|   A Winter Symphony|5457089.clip.mp3|ARPDUDM1187B993570|/nfs/msd/mp3/MSD/...| 687194767362|      1|\n",
      "|TRSOGSR128F428A16|B001CO42BQ|Country Rock,Adul...|        0|I've always liked...|A28H95DNLXHNJ7|         Do You Know|1751486.clip.mp3|AR5QUQY1187FB58AE8|/nfs/msd/mp3/MSD/...| 841813590017|      1|\n",
      "|TRWRMZT128F92C76F|B000009OGW|Alternative Rock,...|        0|This is vintage L...|A3UJJGY799F76I|      I Looooves Liz|3557653.clip.mp3|ARD5EU01187FB3D54D|/nfs/msd/mp3/MSD/...| 901943132160|      1|\n",
      "|TRSOGSR128F428A16|B0000024OG|Folk Rock,Contemp...|        0|Length - 73:33Alo...|A2UO10VW2BLHUM|The 20th Century'...|1751486.clip.mp3|AR5QUQY1187FB58AE8|/nfs/msd/mp3/MSD/...|1099511627777|      1|\n",
      "|TROYIHQ128F930CE4|B001E12ZF2|Noels,Adult Conte...|        0|I love this album...|A3S6S6JWHQ0R3L|Another great album!|5457089.clip.mp3|ARPDUDM1187B993570|/nfs/msd/mp3/MSD/...|1357209665539|      1|\n",
      "+-----------------+----------+--------------------+---------+--------------------+--------------+--------------------+----------------+------------------+--------------------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full.sample(0.01).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "x, sr = librosa.load('/nfs/msd/mp3/MSD/audio/2/9/2937068.clip.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5993, 64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from source.sound_transforms import log_mel_spectrogram\n",
    "\n",
    "log_mel_spectrogram(x,sr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.sound_transforms import log_mel_spectrogram\n",
    "from pyspark.sql.functions import udf, array, struct\n",
    "from pyspark.sql.types import *\n",
    "import librosa\n",
    "import lmdb\n",
    "\n",
    "\n",
    "def write_to_db(row):\n",
    "    path = row[\"path\"]\n",
    "    msd_id = row[\"MSD_track_id\"].encode()\n",
    "    \n",
    "    env = lmdb.open('data/MSD/MSD_ID_to_log_mel_spectrogram.lmdb', subdir=False,\n",
    "            map_size=1e12 )\n",
    "    \n",
    "    with env.begin(write=False) as txn:\n",
    "        data = txn.get(msd_id)\n",
    "    \n",
    "    if data is None:\n",
    "        try:\n",
    "            x, sr = librosa.load(path)\n",
    "        except:\n",
    "            return \"error\"\n",
    "        features = log_mel_spectrogram(x,sr)\n",
    "\n",
    "        with env.begin(write=True) as txn:\n",
    "            txn.put(msd_id, features.tobytes())\n",
    "            \n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "to_db_udf = udf(write_to_db, returnType=ArrayType(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_map_written = filtered_path_map.withColumn(\"written\", to_db_udf(struct(\"*\")))\n",
    "\n",
    "path_map_written.collect()\n",
    "\n",
    "\n",
    "env = lmdb.open('data/MSD/msdid_to_log_mel_spectrogram.lmdb', subdir=False,\n",
    "                map_size=1e12 )\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "env.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+----------------+----------------+------------------+--------------------+\n",
      "|     MSD_track_id|        valence|        arousal |        filename|             label|                path|\n",
      "+-----------------+---------------+----------------+----------------+------------------+--------------------+\n",
      "|TRCUDHE128E0783F2|  1.07008192307|   1.29854404255|  18147.clip.mp3|ARY2Z6Y1187B9BA126|/nfs/msd/mp3/MSD/...|\n",
      "|TRGDPXJ128F4269C6| -1.93524985679| -0.655809808621|1616387.clip.mp3|ARW5XFX1187B9AE42A|/nfs/msd/mp3/MSD/...|\n",
      "|TRJXIXT128E079275| -1.28169934715|    1.3769025696| 164092.clip.mp3|ARK9TRQ1187B99C095|/nfs/msd/mp3/MSD/...|\n",
      "|TRUCKBD128F428F54| -1.05657234488|  0.736206377828|1102335.clip.mp3|ARMZFC81187B9AC52C|/nfs/msd/mp3/MSD/...|\n",
      "|TRWIGBF128F424CDB| -1.70057201199|   1.84244440679|1489051.clip.mp3|ARLSF8H1187B9A76B0|/nfs/msd/mp3/MSD/...|\n",
      "+-----------------+---------------+----------------+----------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deezer = spark.read.csv(\"data/deezer/msd_id_to_emotion.csv\", header=\"true\")\n",
    "deezer = deezer.withColumnRenamed(\"msd_id\", \"MSD_track_id\")\n",
    "deezer = deezer.withColumn(\"MSD_track_id\", sf.substring(sf.col(\"MSD_track_id\"), 0, 17))\n",
    "\n",
    "joined_deezer = deezer.join(path_map, \"MSD_track_id\")\n",
    "\n",
    "joined_deezer.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'psize': 4096,\n",
       " 'depth': 3,\n",
       " 'branch_pages': 20,\n",
       " 'leaf_pages': 2216,\n",
       " 'overflow_pages': 100739872,\n",
       " 'entries': 173775}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_deezer_written = joined_deezer.withColumn(\"written\", to_db_udf(struct(\"*\")))\n",
    "\n",
    "joined_deezer_written.collect()\n",
    "\n",
    "env = lmdb.open('data/MSD/MSD_ID_to_log_mel_spectrogram.lmdb', subdir=False,\n",
    "                map_size=1e12 )\n",
    "\n",
    "env.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "urbansound = spark.read.csv('/nfs/subtasks/urbansound8k/UrbanSound8K/metadata/UrbanSound8K.csv', header=\"true\")\n",
    "\n",
    "urbansound.groupBy('class').count().show()\n",
    "#urbansound.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----+--------+---------+-----+------+-----------+--------------+--------+-----+------+------------+----------+------+--------+-----+-------+-----+---+--------+-----+----------+------+-------+--------+-----+---------+------+---------+---------+-----+------+----+------+-----+-------+-----+--------+----+-------+----+------------+----+-----+-------+-------+-----+----+----------+--------------+-------+----------+----+----+-----+----------+-----+-----+-------+----+----------+--------+----------+----+--------+--------+----+-------+------+-----+----------+-------------+--------+---------+--------+---------+-----+--------+-------+------+-----+-----+-------+----+---------------+---------------+-----------+-----------+----------------+-------+------+-------+------+------+----+----------+---------+-----+-----------+----+--------+------+---+---+------------+------+-----+-------+-----+-----------+-----------+------+-----+-----+---+----+---------+----------+----+----+--------+------+---+----+------------+----+------+----------+-----+-----+----+-----+------+-----------+---------+-------+---+------+----+-------+---+---+----+----+-----+-----+------+---------+-----+-----+-----+-------------+----+-----+----------+-------+--------+-----+-------+-----+----+-------------+------+---------+------+--------+-----+-----+-----+---------+-----------+--------+----+------+----+-----+-----+-------------+---+-----+-------+-----+-----+-------+-----+------+-------+--------------------+\n",
      "|clip_id|no voice|singer|duet|plucking|hard rock|world|bongos|harpsichord|female singing|clasical|sitar|chorus|female opera|male vocal|vocals|clarinet|heavy|silence|beats|men|woodwind|funky|no strings|chimes|foreign|no piano|horns|classical|female|no voices|soft rock|eerie|spacey|jazz|guitar|quiet|no beat|banjo|electric|solo|violins|folk|female voice|wind|happy|ambient|new age|synth|funk|no singing|middle eastern|trumpet|percussion|drum|airy|voice|repetitive|birds|space|strings|bass|harpsicord|medieval|male voice|girl|keyboard|acoustic|loud|classic|string|drums|electronic|not classical|chanting|no violin|not rock|no guitar|organ|no vocal|talking|choral|weird|opera|soprano|fast|acoustic guitar|electric guitar|male singer|man singing|classical guitar|country|violin|electro|reggae|tribal|dark|male opera|no vocals|irish|electronica|horn|operatic|arabic|lol|low|instrumental|trance|chant|strange|drone|synthesizer|heavy metal|modern|disco|bells|man|deep|fast beat|industrial|hard|harp|no flute|jungle|pop|lute|female vocal|oboe|mellow|orchestral|viola|light|echo|piano|celtic|male vocals|orchestra|eastern|old|flutes|punk|spanish|sad|sax|slow|male|blues|vocal|indian|no singer|scary|india|woman|woman singing|rock|dance|piano solo|guitars|no drums|jazzy|singing|cello|calm|female vocals|voices|different|techno|clapping|house|monks|flute|not opera|not english|oriental|beat|upbeat|soft|noise|choir|female singer|rap|metal|hip hop|quick|water|baroque|women|fiddle|english|            mp3_path|\n",
      "+-------+--------+------+----+--------+---------+-----+------+-----------+--------------+--------+-----+------+------------+----------+------+--------+-----+-------+-----+---+--------+-----+----------+------+-------+--------+-----+---------+------+---------+---------+-----+------+----+------+-----+-------+-----+--------+----+-------+----+------------+----+-----+-------+-------+-----+----+----------+--------------+-------+----------+----+----+-----+----------+-----+-----+-------+----+----------+--------+----------+----+--------+--------+----+-------+------+-----+----------+-------------+--------+---------+--------+---------+-----+--------+-------+------+-----+-----+-------+----+---------------+---------------+-----------+-----------+----------------+-------+------+-------+------+------+----+----------+---------+-----+-----------+----+--------+------+---+---+------------+------+-----+-------+-----+-----------+-----------+------+-----+-----+---+----+---------+----------+----+----+--------+------+---+----+------------+----+------+----------+-----+-----+----+-----+------+-----------+---------+-------+---+------+----+-------+---+---+----+----+-----+-----+------+---------+-----+-----+-----+-------------+----+-----+----------+-------+--------+-----+-------+-----+----+-------------+------+---------+------+--------+-----+-----+-----+---------+-----------+--------+----+------+----+-----+-----+-------------+---+-----+-------+-----+-----+-------+-----+------+-------+--------------------+\n",
      "|      2|       0|     0|   0|       0|        0|    0|     0|          0|             0|       0|    0|     0|           0|         0|     0|       0|    0|      0|    0|  0|       0|    0|         0|     0|      0|       0|    0|        1|     0|        0|        0|    0|     0|   0|     0|    0|      0|    0|       0|   0|      0|   0|           0|   0|    0|      0|      0|    0|   0|         0|             0|      0|         0|   0|   0|    0|         0|    0|    0|      1|   0|         0|       0|         0|   0|       0|       0|   0|      0|     0|    0|         0|            0|       0|        0|       0|        0|    0|       0|      0|     0|    0|    1|      0|   0|              0|              0|          0|          0|               0|      0|     1|      0|     0|     0|   0|         0|        0|    0|          0|   0|       0|     0|  0|  0|           0|     0|    0|      0|    0|          0|          0|     0|    0|    0|  0|   0|        0|         0|   0|   0|       0|     0|  0|   0|           0|   0|     0|         0|    0|    0|   0|    0|     0|          0|        0|      0|  0|     0|   0|      0|  0|  0|   0|   0|    0|    0|     0|        0|    0|    0|    0|            0|   0|    0|         0|      0|       0|    0|      0|    0|   0|            0|     0|        0|     0|       0|    0|    0|    0|        0|          0|       0|   0|     0|   0|    0|    0|            0|  0|    0|      0|    0|    0|      0|    0|     0|      0|f/american_bach_s...|\n",
      "|      6|       0|     0|   0|       0|        0|    0|     0|          0|             0|       0|    0|     0|           0|         0|     0|       0|    0|      0|    0|  0|       0|    0|         0|     0|      0|       0|    0|        1|     0|        0|        0|    0|     0|   0|     0|    0|      0|    0|       0|   0|      1|   0|           0|   0|    0|      0|      0|    0|   0|         0|             0|      0|         0|   0|   0|    0|         0|    0|    0|      1|   0|         0|       0|         0|   0|       0|       0|   0|      1|     0|    0|         0|            0|       0|        0|       0|        0|    0|       0|      0|     0|    0|    1|      0|   0|              0|              0|          0|          0|               0|      0|     1|      0|     0|     0|   0|         0|        0|    0|          0|   0|       0|     0|  0|  0|           0|     0|    0|      0|    0|          0|          0|     0|    0|    0|  0|   0|        0|         0|   0|   0|       0|     0|  0|   0|           0|   0|     0|         0|    0|    0|   0|    0|     0|          0|        0|      0|  0|     0|   0|      0|  0|  0|   0|   0|    0|    0|     0|        0|    0|    0|    0|            0|   0|    0|         0|      0|       0|    0|      0|    0|   0|            0|     0|        0|     0|       0|    0|    0|    0|        0|          0|       0|   0|     0|   0|    0|    0|            0|  0|    0|      0|    0|    0|      1|    0|     0|      0|f/american_bach_s...|\n",
      "|     10|       0|     0|   0|       0|        0|    0|     0|          0|             0|       0|    0|     0|           0|         0|     0|       0|    0|      0|    0|  0|       0|    0|         0|     0|      0|       0|    0|        1|     0|        0|        0|    0|     0|   0|     0|    0|      0|    0|       0|   0|      0|   0|           0|   0|    0|      0|      0|    0|   0|         0|             0|      0|         0|   0|   0|    0|         0|    0|    0|      0|   0|         0|       0|         0|   0|       0|       0|   0|      1|     0|    0|         0|            0|       0|        0|       0|        0|    0|       0|      0|     0|    0|    1|      0|   0|              0|              0|          0|          0|               0|      0|     0|      0|     0|     0|   0|         0|        0|    0|          0|   0|       0|     0|  0|  0|           0|     0|    0|      0|    0|          0|          0|     0|    0|    0|  0|   0|        0|         0|   0|   0|       0|     0|  0|   0|           0|   0|     0|         0|    0|    0|   0|    0|     0|          0|        0|      0|  0|     0|   0|      0|  0|  0|   0|   0|    0|    0|     0|        0|    0|    0|    0|            0|   0|    0|         0|      0|       0|    0|      0|    0|   0|            0|     0|        0|     0|       0|    0|    0|    0|        0|          0|       0|   0|     0|   0|    0|    0|            0|  0|    0|      0|    0|    0|      0|    0|     0|      0|f/american_bach_s...|\n",
      "|     11|       0|     0|   0|       0|        0|    0|     0|          0|             0|       0|    0|     0|           0|         0|     0|       0|    0|      0|    0|  0|       0|    0|         0|     0|      0|       0|    0|        0|     0|        0|        0|    0|     0|   0|     0|    1|      0|    0|       0|   0|      0|   0|           0|   0|    0|      0|      0|    0|   0|         0|             0|      0|         0|   0|   0|    0|         0|    0|    0|      0|   0|         0|       0|         0|   0|       0|       0|   0|      0|     0|    0|         0|            0|       0|        0|       0|        0|    0|       0|      0|     0|    0|    1|      0|   0|              0|              0|          0|          0|               0|      0|     0|      0|     0|     0|   0|         0|        0|    0|          0|   0|       0|     0|  0|  0|           0|     0|    0|      0|    0|          0|          0|     0|    0|    0|  0|   0|        0|         0|   0|   0|       0|     0|  0|   0|           0|   0|     0|         0|    0|    0|   0|    0|     0|          0|        0|      0|  0|     0|   0|      0|  0|  0|   0|   0|    0|    0|     0|        0|    0|    0|    0|            0|   0|    0|         0|      0|       0|    0|      0|    0|   0|            0|     0|        0|     0|       0|    0|    0|    0|        0|          0|       0|   0|     0|   0|    0|    0|            0|  0|    0|      0|    0|    0|      0|    0|     0|      0|f/american_bach_s...|\n",
      "|     12|       0|     0|   0|       0|        0|    0|     0|          0|             0|       0|    0|     0|           0|         0|     0|       0|    0|      0|    0|  0|       0|    0|         0|     0|      0|       0|    0|        1|     0|        0|        0|    0|     0|   0|     0|    0|      0|    0|       0|   0|      1|   0|           0|   0|    0|      0|      0|    0|   0|         0|             0|      0|         0|   0|   0|    0|         0|    0|    0|      1|   0|         0|       0|         0|   0|       0|       0|   0|      1|     0|    0|         0|            0|       0|        0|       0|        0|    0|       0|      0|     0|    0|    0|      0|   0|              0|              0|          0|          0|               0|      0|     1|      0|     0|     0|   0|         0|        0|    0|          0|   0|       0|     0|  0|  0|           0|     0|    0|      0|    0|          0|          0|     0|    0|    0|  0|   0|        0|         0|   0|   0|       0|     0|  0|   0|           0|   0|     0|         0|    0|    0|   0|    0|     0|          0|        0|      0|  0|     0|   0|      0|  0|  0|   0|   0|    0|    0|     0|        0|    0|    0|    0|            0|   0|    0|         0|      0|       0|    0|      0|    0|   0|            0|     0|        0|     0|       0|    0|    0|    0|        0|          0|       0|   0|     0|   0|    0|    0|            0|  0|    0|      0|    0|    0|      0|    0|     0|      0|f/american_bach_s...|\n",
      "+-------+--------+------+----+--------+---------+-----+------+-----------+--------------+--------+-----+------+------------+----------+------+--------+-----+-------+-----+---+--------+-----+----------+------+-------+--------+-----+---------+------+---------+---------+-----+------+----+------+-----+-------+-----+--------+----+-------+----+------------+----+-----+-------+-------+-----+----+----------+--------------+-------+----------+----+----+-----+----------+-----+-----+-------+----+----------+--------+----------+----+--------+--------+----+-------+------+-----+----------+-------------+--------+---------+--------+---------+-----+--------+-------+------+-----+-----+-------+----+---------------+---------------+-----------+-----------+----------------+-------+------+-------+------+------+----+----------+---------+-----+-----------+----+--------+------+---+---+------------+------+-----+-------+-----+-----------+-----------+------+-----+-----+---+----+---------+----------+----+----+--------+------+---+----+------------+----+------+----------+-----+-----+----+-----+------+-----------+---------+-------+---+------+----+-------+---+---+----+----+-----+-----+------+---------+-----+-----+-----+-------------+----+-----+----------+-------+--------+-----+-------+-----+----+-------------+------+---------+------+--------+-----+-----+-----+---------+-----------+--------+----+------+----+-----+-----+-------------+---+-----+-------+-----+-----+-------+-----+------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtat = spark.read.option(\"sep\", \"\\t\").csv('/nfs/subtasks/MagnaTagATune/annotations_final.csv', header=\"true\")\n",
    "\n",
    "#mtat.groupBy('no voice').count().show()\n",
    "mtat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|written|count|\n",
      "+-------+-----+\n",
      "|   null|18334|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_deezer_written.groupBy('written').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'TRAAAAV128F421A32'\n",
      "(5993, 64)\n",
      "b'TRAAACV128F423E09'\n",
      "(2998, 64)\n",
      "b'TRAAADT12903CCC33'\n",
      "(5998, 64)\n",
      "b'TRAAAED128E0783FA'\n",
      "(5993, 64)\n",
      "b'TRAAAEF128F427342'\n",
      "(2998, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "env = lmdb.open('data/MSD/msdid_to_log_mel_spectrogram.lmdb', subdir=False,\n",
    "                map_size=1e12 )\n",
    "\n",
    "with env.begin() as txn:\n",
    "    for (key, value), i in zip(txn.cursor(), range(5)):\n",
    "        print(key)\n",
    "        print(np.reshape(np.frombuffer(value), (-1, 64)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_id</th>\n",
       "      <th>album_mbid</th>\n",
       "      <th>MSD_track_id</th>\n",
       "      <th>recording_mbid</th>\n",
       "      <th>artist_mbid</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00005YQOV</td>\n",
       "      <td>77944b8c-f753-4c7c-84ba-a48fbf518667</td>\n",
       "      <td>TRJIKJU128F930BF28</td>\n",
       "      <td>68c38213-65ba-4c1e-ac20-76883b512993</td>\n",
       "      <td>0a6f37da-2a2a-4308-896a-7c34b968b0b3</td>\n",
       "      <td>Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00005YQOV</td>\n",
       "      <td>77944b8c-f753-4c7c-84ba-a48fbf518667</td>\n",
       "      <td>TRLCVKT128F930BF18</td>\n",
       "      <td>f5c25488-4fbc-4ade-9cd4-431ae3fe3737</td>\n",
       "      <td>0a6f37da-2a2a-4308-896a-7c34b968b0b3</td>\n",
       "      <td>Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00005YQOV</td>\n",
       "      <td>77944b8c-f753-4c7c-84ba-a48fbf518667</td>\n",
       "      <td>TRBQSIG128F930BEFC</td>\n",
       "      <td>e76bbfcc-f94a-425d-bf13-d4e8d32df173</td>\n",
       "      <td>0a6f37da-2a2a-4308-896a-7c34b968b0b3</td>\n",
       "      <td>Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00005YQOV</td>\n",
       "      <td>77944b8c-f753-4c7c-84ba-a48fbf518667</td>\n",
       "      <td>TRGQLER128F930BF59</td>\n",
       "      <td>9def0715-4be3-4755-b546-f0335e03447b</td>\n",
       "      <td>0a6f37da-2a2a-4308-896a-7c34b968b0b3</td>\n",
       "      <td>Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00005YQOV</td>\n",
       "      <td>77944b8c-f753-4c7c-84ba-a48fbf518667</td>\n",
       "      <td>TRQPGRM128F930BEEA</td>\n",
       "      <td>9fe52229-a318-499e-af96-0903294366b1</td>\n",
       "      <td>0a6f37da-2a2a-4308-896a-7c34b968b0b3</td>\n",
       "      <td>Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazon_id                            album_mbid        MSD_track_id  \\\n",
       "0  B00005YQOV  77944b8c-f753-4c7c-84ba-a48fbf518667  TRJIKJU128F930BF28   \n",
       "1  B00005YQOV  77944b8c-f753-4c7c-84ba-a48fbf518667  TRLCVKT128F930BF18   \n",
       "2  B00005YQOV  77944b8c-f753-4c7c-84ba-a48fbf518667  TRBQSIG128F930BEFC   \n",
       "3  B00005YQOV  77944b8c-f753-4c7c-84ba-a48fbf518667  TRGQLER128F930BF59   \n",
       "4  B00005YQOV  77944b8c-f753-4c7c-84ba-a48fbf518667  TRQPGRM128F930BEEA   \n",
       "\n",
       "                         recording_mbid                           artist_mbid  \\\n",
       "0  68c38213-65ba-4c1e-ac20-76883b512993  0a6f37da-2a2a-4308-896a-7c34b968b0b3   \n",
       "1  f5c25488-4fbc-4ade-9cd4-431ae3fe3737  0a6f37da-2a2a-4308-896a-7c34b968b0b3   \n",
       "2  e76bbfcc-f94a-425d-bf13-d4e8d32df173  0a6f37da-2a2a-4308-896a-7c34b968b0b3   \n",
       "3  9def0715-4be3-4755-b546-f0335e03447b  0a6f37da-2a2a-4308-896a-7c34b968b0b3   \n",
       "4  9fe52229-a318-499e-af96-0903294366b1  0a6f37da-2a2a-4308-896a-7c34b968b0b3   \n",
       "\n",
       "                                              genres  \n",
       "0  Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...  \n",
       "1  Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...  \n",
       "2  Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...  \n",
       "3  Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...  \n",
       "4  Vocal Jazz,Jazz,Traditional Vocal Pop,Pop,Mode...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mumu_dir = '../mumu/MuMu_dataset/'\n",
    "df = pd.read_csv(mumu_dir + '/MuMu_dataset_multi-label.csv')\n",
    "\n",
    "### REMEMBER TO SUBSTRING MSD_ID\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0009832382202148438, 0.06783390045166016)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from source.utils import Timer\n",
    "import random\n",
    "\n",
    "\n",
    "db = []\n",
    "\n",
    "with open(mumu_dir + '/MuMu_dataset_multi-label.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        if row[0] == \"amazon_id\":\n",
    "            continue\n",
    "            \n",
    "        db.append(row[2])\n",
    "\n",
    "\n",
    "t1, t2 = 0, 0        \n",
    "for _ in range(1000):\n",
    "    \n",
    "    index = random.randint(0, 140000)\n",
    "\n",
    "    with Timer() as t:\n",
    "        db[index]\n",
    "\n",
    "    t1 += t()\n",
    "    \n",
    "    with Timer() as t:\n",
    "        df.iloc[index][\"MSD_track_id\"]\n",
    "        \n",
    "    t2 += t()\n",
    "    \n",
    "t1,t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRDTYCI128F93015F'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lmdb\n",
    "\n",
    "song_env = lmdb.open(\"data/MSD/MSD_ID_to_log_mel_spectrogram.lmdb\", readonly=True, lock=False, \n",
    "                                    max_spare_txns=2, subdir=False, readahead=False, meminit=False)\n",
    "\n",
    "msd_id = db[55][:17]\n",
    "with song_env.begin() as txn:\n",
    "    data = txn.get(msd_id.encode())\n",
    "    \n",
    "msd_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
